from langchain_ollama import OllamaEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document # Still needed for type hinting
from langchain_community.document_loaders import PyPDFLoader # <-- New Import!
from langchain_text_splitters import RecursiveCharacterTextSplitter# <-- New Import!
import os 
# from pypdf import PdfReader # PyPDFLoader handles this internally

# --- 1. Configuration ---

# Path to your PDF file
PDF_PATH = 'General HR Queries.pdf' 

# Ollama Embeddings (correctly configured)
embeddings = OllamaEmbeddings(
    model="mxbai-embed-large",
)

db_location = "./chroma_hr_db"

# Check if the database needs to be built
add_documents = not os.path.exists(db_location)

# --- 2. Ingestion or Loading Logic ---

if add_documents:
    print("Building new vector store from PDF...")
    
    # **STEP A: Load the PDF document**
    loader = PyPDFLoader(PDF_PATH)
    # The loader returns a list of LangChain Documents, one for each page
    pages = loader.load() 

    # **STEP B: Split the text into smaller, manageable chunks**
    # This is crucial for RAG performance
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    # 'documents' now holds the split chunks
    documents = text_splitter.split_documents(pages)

    print(f"Split PDF into {len(documents)} text chunks.")

    # **STEP C: Create, embed, and persist the database**
    vector_store = Chroma.from_documents(
        documents=documents, 
        embedding=embeddings, 
        persist_directory=db_location,
        # IDs are automatically generated by Chroma when not explicitly passed
    )
    print(f"Successfully built and saved Chroma DB at: {db_location}")
    
else:
    # Load the existing database if it already exists
    print(f"Loading existing vector store from: {db_location}")
    vector_store = Chroma(
        persist_directory=db_location, 
        embedding_function=embeddings
    )

# --- 3. Create Retriever ---
# This remains the same, using the created or loaded vector_store
retriever = vector_store.as_retriever(search_kwargs={"k": 10})

print("Retriever initialized successfully.")